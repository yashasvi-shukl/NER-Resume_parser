{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "a4103022",
      "metadata": {
        "collapsed": true,
        "id": "a4103022"
      },
      "outputs": [],
      "source": [
        "!pip install -U spacy\n",
        "!pip install spacy-transformers\n",
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "15908c19",
      "metadata": {
        "id": "15908c19"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from spacy import displacy\n",
        "import sys, fitz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "6887f800",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6887f800",
        "outputId": "819a30b0-d8c1-4316-e4bb-4b9c9d8bd367"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.4.3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "spacy.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "910d1ce8",
      "metadata": {
        "id": "910d1ce8"
      },
      "outputs": [],
      "source": [
        "# Loading JSON file (dataset)\n",
        "cv_data = json.load(open(\"CV-Parsing-using-Spacy-3/data/training/train_data.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "0b707c21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b707c21",
        "outputId": "5c32e844-9ab3-43da-d56d-4e03b0985868"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "len(cv_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "b3fce0ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3fce0ab",
        "outputId": "949ed02d-fb3b-456b-af09-d3a79cc5d747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "CV-Parsing-using-Spacy-3/data/training/config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "# Setting up configuration file\n",
        "!python -m spacy init fill-config CV-Parsing-using-Spacy-3/data/training/base_config.cfg CV-Parsing-using-Spacy-3/data/training/config.cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "30ab5f1a",
      "metadata": {
        "id": "30ab5f1a"
      },
      "outputs": [],
      "source": [
        "def get_spacy_doc(file, data):\n",
        "    nlp = spacy.blank('en')\n",
        "    db = DocBin()\n",
        "    \n",
        "    for text, annot in tqdm(data):\n",
        "        doc = nlp.make_doc(text)\n",
        "        annot = annot['entities']\n",
        "        \n",
        "        ents = []\n",
        "        entity_indices = []\n",
        "        \n",
        "        # below code will help to identify if there is any overlapping entity. If yes, then we'll keep only 1st entity and skip other\n",
        "        for start, end , label in annot:\n",
        "            skip_entitiy = False\n",
        "            for idx in range(start, end):\n",
        "                if idx in entity_indices:\n",
        "                    skip_entitiy = True\n",
        "                    break\n",
        "            if skip_entitiy:\n",
        "                continue\n",
        "                \n",
        "                \n",
        "            entity_indices = entity_indices + list(range(start, end))\n",
        "            \n",
        "            #Getting span of data\n",
        "            try:\n",
        "                span = doc.char_span(start, end, label = label, alignment_mode='strict')\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            # If the given index span has no value the we'll add those data into error.txt file\n",
        "            if span is None:\n",
        "                err_data = str([start, end]) + \"    \" + str(text) +'\\n'\n",
        "                file.write(err_data)\n",
        "                \n",
        "            else:\n",
        "                ents.append(span)\n",
        "                \n",
        "                \n",
        "        try:\n",
        "          # Setting up custom entities and adding it to docbin object\n",
        "            doc.ents = ents\n",
        "            db.add(doc)\n",
        "            \n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "    return db\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "bd617e39",
      "metadata": {
        "id": "bd617e39"
      },
      "outputs": [],
      "source": [
        "# Creating train and test dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(cv_data, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "e293ac5c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e293ac5c",
        "outputId": "a2332f52-0d35-41f8-c2d3-686400c0386f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "len(train), len(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "ca7f2196",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca7f2196",
        "outputId": "8ef2c7e8-04eb-4936-863f-80735388b8f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 160/160 [00:01<00:00, 91.07it/s] \n",
            "100%|██████████| 40/40 [00:00<00:00, 80.34it/s]\n"
          ]
        }
      ],
      "source": [
        "file = open('error.txt', 'w', encoding='utf-8')\n",
        "\n",
        "#Extracting and saving spacy file to the disk for training purpose\n",
        "db = get_spacy_doc(file, train)\n",
        "db.to_disk('train_data.spacy')\n",
        "\n",
        "db = get_spacy_doc(file, test)\n",
        "db.to_disk('test_data.spacy')\n",
        "\n",
        "\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "43476a18",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43476a18",
        "outputId": "fa17c2b7-bb43-4b13-f163-0bf0e569b8aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-11-15 14:21:11,829] [INFO] Set up nlp object from config\n",
            "INFO:spacy:Set up nlp object from config\n",
            "[2022-11-15 14:21:11,840] [INFO] Pipeline: ['transformer', 'ner']\n",
            "INFO:spacy:Pipeline: ['transformer', 'ner']\n",
            "[2022-11-15 14:21:11,844] [INFO] Created vocabulary\n",
            "INFO:spacy:Created vocabulary\n",
            "[2022-11-15 14:21:11,845] [INFO] Finished initializing nlp object\n",
            "INFO:spacy:Finished initializing nlp object\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2022-11-15 14:21:20,296] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "INFO:spacy:Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0        8898.86   1549.18    0.54    0.28    9.15    0.01\n",
            "  3     200      231487.72  75928.46   14.27   15.98   12.90    0.14\n",
            "  6     400       40334.34  31942.48   32.07   23.04   52.70    0.32\n",
            " 10     600        9575.79  27657.92   24.40   19.00   34.12    0.24\n",
            " 13     800        5734.78  26473.72   29.29   22.29   42.72    0.29\n",
            " 17    1000        3525.55  24841.00   28.17   21.33   41.47    0.28\n",
            " 20    1200       11424.82  23532.61   55.66   51.66   60.33    0.56\n",
            " 24    1400        1774.26  22536.33   56.02   61.67   51.32    0.56\n",
            " 27    1600        1404.35  20765.58   54.21   67.08   45.49    0.54\n",
            " 31    1800         739.47  20870.38   60.38   66.84   55.06    0.60\n",
            " 34    2000        1658.02  18790.31   55.22   68.66   46.19    0.55\n",
            " 37    2200        1133.75  18773.19   58.94   63.96   54.65    0.59\n",
            " 41    2400         558.47  17028.83   57.70   68.85   49.65    0.58\n",
            " 44    2600         425.23  16310.53   58.98   65.65   53.54    0.59\n",
            " 48    2800         461.48  14921.22   51.90   68.56   41.75    0.52\n",
            " 51    3000         528.32  13188.66   58.73   69.92   50.62    0.59\n",
            " 55    3200         401.88  11833.05   60.42   63.41   57.70    0.60\n",
            " 58    3400        7016.83   9781.68   53.04   72.71   41.75    0.53\n",
            " 62    3600         627.87   8280.82   55.86   60.88   51.60    0.56\n",
            " 65    3800         416.79   6011.28   54.79   71.59   44.38    0.55\n",
            " 68    4000         604.47   4762.06   58.32   64.86   52.98    0.58\n",
            " 72    4200         597.61   3150.65   59.13   65.82   53.68    0.59\n",
            " 75    4400         600.02   2264.76   59.63   70.38   51.73    0.60\n",
            " 79    4600         681.83   1487.23   54.62   68.33   45.49    0.55\n",
            " 82    4800         735.37    987.24   56.48   73.39   45.91    0.56\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "output/model-last\n"
          ]
        }
      ],
      "source": [
        "# Training the custom spacy NER model\n",
        "!python -m spacy train CV-Parsing-using-Spacy-3/data/training/config.cfg --output ./output --paths.train ./train_data.spacy --paths.dev ./test_data.spacy --gpu-id 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "41de8d3b",
      "metadata": {
        "id": "41de8d3b"
      },
      "outputs": [],
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Test"
      ],
      "metadata": {
        "id": "OmA9KBqwg0CU"
      },
      "id": "OmA9KBqwg0CU"
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('/content/output/model-best')  # Loading best model"
      ],
      "metadata": {
        "id": "1H3kRcSkg2NQ"
      },
      "id": "1H3kRcSkg2NQ",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.get_pipe(\"ner\").labels  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBVdOl7Jjv8S",
        "outputId": "028af6e3-8965-460b-a5d4-e24d333ad4fa"
      },
      "id": "eBVdOl7Jjv8S",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('College Name',\n",
              " 'Companies worked at',\n",
              " 'Degree',\n",
              " 'Designation',\n",
              " 'Email Address',\n",
              " 'Graduation Year',\n",
              " 'Location',\n",
              " 'Name',\n",
              " 'Skills',\n",
              " 'UNKNOWN',\n",
              " 'Years of Experience')"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting up colors for custom entities\n",
        "colors = {\n",
        "    'College Name' : '#E6B0AA',\n",
        "    'Companies worked at' : '#AF7AC5', \n",
        "    'Degree' : '#5499C7', \n",
        "    'Designation' : '#5DADE2', \n",
        "    'Email Addresss' : '#48C9B0', \n",
        "    'Graduation Year' : '#73C6B6', \n",
        "    'Location' : '#2ECC71', \n",
        "    'Name' : '#F9E79F', \n",
        "    'Skills' : '#EB984E', \n",
        "    'UNKNOWN' : '#D35400', \n",
        "    'Years of Experience' : '#839192'}\n",
        "\n",
        "\n",
        "options = {\"ents\": list(nlp.get_pipe(\"ner\").labels), \"colors\": colors}"
      ],
      "metadata": {
        "id": "K3oCmLEAhkIj"
      },
      "id": "K3oCmLEAhkIj",
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading resume \n",
        "fname = '/content/CV-Parsing-using-Spacy-3/data/test/Smith Resume.pdf'\n",
        "doc = fitz.open(fname)"
      ],
      "metadata": {
        "id": "Rk3FFc8NiLmr"
      },
      "id": "Rk3FFc8NiLmr",
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting resume into text\n",
        "text = [page.get_text() for page in doc][0].strip().split()\n",
        "text = \" \".join(text)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "yn55IwEQiida",
        "outputId": "d7b99022-0ea6-4b04-910a-3c0d5abc2fca"
      },
      "id": "yn55IwEQiida",
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Michael Smith BI / Big Data/ Azure Manchester, UK- Email me on Indeed: indeed.com/r/falicent/140749dace5dc26f 10+ years of Experience in Designing, Development, Administration, Analysis, Management inthe Business Intelligence Data warehousing, Client Server Technologies, Web-based Applications, cloud solutions and Databases. Data warehouse: Data analysis, star/ snow flake schema data modeling and design specific todata warehousing and business intelligence environment. Database: Experience in database designing, scalability, back-up and recovery, writing andoptimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes. Cloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL Azure, StreamAnalytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure data lake analytics(U-SQL). Big Data: Worked Azure data lake store/analytics for big data processing and Azure data factoryto schedule U-SQL jobs. Designed and developed end to end big data solution for data insights. Willing to relocate: Anywhere WORK EXPERIENCESoftware Engineer Microsoft - Manchester, UK. December 2015 to Present 1. Microsoft Rewards Live dashboards: Description: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping online. Microsoft Rewards members can earn points when searching with Bing, browsing with Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft rewards website. Rewards live dashboards gives a live picture of usage world-wide and by markets like US, Canada, Australia, new user registration count, top/bottom performing rewards offers, orders stats and weekly trends of user activities, orders and new user registrations. the PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes. Technology/Tools used Event hub, stream analytics and Power BI. Responsibilities Created stream analytics jobs to process event hub data Created Power BI live dashboard to show live usage traffic, weekly trends, cards, charts to showtop/bottom 10 offers and usage metrics. 2. Microsoft Rewards Data Insights: Description: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping online. Microsoft Rewards members can earn points when searching with Bing, browsing with Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft rewards website. Rewards data insights is data analytics and reporting platform, processes 20 million users daily activities and redemption across different markets like US, Canada, Australia. Technology/Tools used Cosmos (Microsoft big-data platform), c#, X-flow job monitoring, Power BI. Responsibilities'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting text into spacy doc and then printing the extracted entities\n",
        "\n",
        "doc = nlp(text)\n",
        "text_list = []\n",
        "\n",
        "for ent in doc.ents:\n",
        "  if ent.text not in text_list:\n",
        "    print(ent.text, '\\t\\t\\t\\t\\t', ent.label_)\n",
        "    text_list.append(ent.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bb2gmd6jNGz",
        "outputId": "edab68ce-8004-493d-845b-d0e6f9abdc2e"
      },
      "id": "2Bb2gmd6jNGz",
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manchester \t\t\t\t\t Location\n",
            "indeed.com/r/falicent/140749dace5dc26f \t\t\t\t\t Email Address\n",
            "Microsoft \t\t\t\t\t Companies worked at\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "displacy.render(doc, style=\"ent\", jupyter = True, options = options)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "zSQaAvjPjrsa",
        "outputId": "35267baf-0851-4513-f371-6bcfc8abfaba"
      },
      "id": "zSQaAvjPjrsa",
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Michael Smith BI / Big Data/ Azure \n",
              "<mark class=\"entity\" style=\"background: #2ECC71; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Manchester\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Location</span>\n",
              "</mark>\n",
              ", UK- Email me on Indeed: \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    indeed.com/r/falicent/140749dace5dc26f\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Email Address</span>\n",
              "</mark>\n",
              " 10+ years of Experience in Designing, Development, Administration, Analysis, Management inthe Business Intelligence Data warehousing, Client Server Technologies, Web-based Applications, cloud solutions and Databases. Data warehouse: Data analysis, star/ snow flake schema data modeling and design specific todata warehousing and business intelligence environment. Database: Experience in database designing, scalability, back-up and recovery, writing andoptimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes. Cloud platform: Worked on \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " Azure cloud services like Document DB, SQL Azure, StreamAnalytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure data lake analytics(U-SQL). Big Data: Worked Azure data lake store/analytics for big data processing and Azure data factoryto schedule U-SQL jobs. Designed and developed end to end big data solution for data insights. Willing to relocate: Anywhere WORK EXPERIENCESoftware Engineer \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " - Manchester, UK. December 2015 to Present 1. \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " Rewards Live dashboards: Description: - \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " rewards is loyalty program that rewards Users for browsing and shopping online. \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " Rewards members can earn points when searching with Bing, browsing with \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " Edge and making purchases at the Xbox Store, the Windows Store and the \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " rewards website. Rewards live dashboards gives a live picture of usage world-wide and by markets like US, Canada, Australia, new user registration count, top/bottom performing rewards offers, orders stats and weekly trends of user activities, orders and new user registrations. the PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes. Technology/Tools used Event hub, stream analytics and Power BI. Responsibilities Created stream analytics jobs to process event hub data Created Power BI live dashboard to show live usage traffic, weekly trends, cards, charts to showtop/bottom 10 offers and usage metrics. 2. \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " Rewards Data Insights: Description: - \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " rewards is loyalty program that rewards Users for browsing and shopping online. \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " Rewards members can earn points when searching with Bing, browsing with \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " Edge and making purchases at the Xbox Store, the Windows Store and the \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the \n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " rewards website. Rewards data insights is data analytics and reporting platform, processes 20 million users daily activities and redemption across different markets like US, Canada, Australia. Technology/Tools used Cosmos (\n",
              "<mark class=\"entity\" style=\"background: #AF7AC5; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Microsoft\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Companies worked at</span>\n",
              "</mark>\n",
              " big-data platform), c#, X-flow job monitoring, Power BI. Responsibilities</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kg0ChpaReX1i"
      },
      "id": "Kg0ChpaReX1i",
      "execution_count": 146,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}